{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:37:38.913042Z",
     "start_time": "2024-04-29T16:37:38.895910Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Написать программу, которая разделяет исходную выборку на обучающую и тестовую (training set, validation set, test set), если такое разделение не предусмотрено предложенным набором данных."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e216b9172dc6b4d7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выборки сохранены в CSV файлы.\n"
     ]
    }
   ],
   "source": [
    "# Чтение файла ARFF и загрузка данных\n",
    "data, meta = arff.loadarff('seismic-bumps.arff')\n",
    "\n",
    "# Преобразование данных в DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "# Разделение данных на обучающую (70%), валидационную (15%) и тестовую (15%) выборки\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# Сохранение обучающей выборки в CSV файл\n",
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "Xy_train.to_csv('train_data.csv', index=False)\n",
    "\n",
    "# Сохранение валидационной выборки в CSV файл\n",
    "Xy_val = pd.concat([X_val, y_val], axis=1)\n",
    "Xy_val.to_csv('val_data.csv', index=False)\n",
    "\n",
    "# Сохранение тестовой выборки в CSV файл\n",
    "Xy_test = pd.concat([X_test, y_test], axis=1)\n",
    "Xy_test.to_csv('test_data.csv', index=False)\n",
    "\n",
    "print(\"Выборки сохранены в CSV файлы.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:37:48.453607Z",
     "start_time": "2024-04-29T16:37:47.690934Z"
    }
   },
   "id": "c4511d9753a9f88d",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Произвести масштабирование признаков (scaling)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79d7fbaa55b42221"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Масштабирование числовых признаков обучающей выборки выполнено.\n",
      "Масштабированные числовые признаки обучающей выборки (стандартизация):\n",
      "[[-0.30049373  0.08183243  0.54158503 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.37713439 -0.77528822 -0.69698126 ...  0.         -0.1269119\n",
      "  -0.11905458]\n",
      " [-0.22044203  0.21120914  0.50442804 ...  0.          0.7178613\n",
      "   0.79774021]\n",
      " ...\n",
      " [-0.17907767 -0.08707604  0.55397069 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.32065778 -0.2775473  -0.43688234 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.34552821 -0.28832869 -0.8827662  ...  0.         -0.24210825\n",
      "  -0.22092067]]\n",
      "\n",
      "Нормализованные числовые признаки обучающей выборки:\n",
      "[[0.00912716 0.13454045 0.11334825 ... 0.         0.         0.        ]\n",
      " [0.00228853 0.02521201 0.03877703 ... 0.         0.00597015 0.005     ]\n",
      " [0.01627015 0.15104286 0.11111111 ... 0.         0.04975124 0.05      ]\n",
      " ...\n",
      " [0.01996109 0.11299565 0.11409396 ... 0.         0.         0.        ]\n",
      " [0.00732793 0.08870044 0.05443699 ... 0.         0.         0.        ]\n",
      " [0.00510874 0.08732523 0.02759135 ... 0.         0.         0.        ]]\n",
      "Масштабирование числовых признаков валидационной выборки выполнено.\n",
      "\n",
      "Масштабированные числовые признаки валидационной выборки (стандартизация):\n",
      "[[-0.37329156 -0.85435176 -0.70936692 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.30623639  0.33878894  0.70259865 ...  0.         -0.22290886\n",
      "  -0.20054745]\n",
      " [-0.29505333  0.24175641  2.65953339 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " ...\n",
      " [-0.05088269  0.15191148 -0.16439775 ...  0.          1.86982475\n",
      "   1.8164011 ]\n",
      " [-0.21910352  0.05847275  3.11780291 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.19134017  0.07823864  0.19478647 ...  0.         -0.1269119\n",
      "  -0.11905458]]\n",
      "\n",
      "Нормализованные числовые признаки валидационной выборки:\n",
      "[[0.00263143 0.01512721 0.03803132 ... 0.         0.         0.        ]\n",
      " [0.00861474 0.16731607 0.12304251 ... 0.         0.00099502 0.001     ]\n",
      " [0.00961261 0.15493926 0.24086503 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.0313999  0.14347926 0.07084265 ... 0.         0.10945274 0.1       ]\n",
      " [0.01638959 0.13156085 0.26845638 ... 0.         0.         0.        ]\n",
      " [0.01886691 0.13408205 0.09246831 ... 0.         0.00597015 0.005     ]]\n",
      "Масштабирование числовых признаков тестовой выборки выполнено.\n",
      "\n",
      "Масштабированные числовые признаки тестовой выборки (стандартизация):\n",
      "[[-0.34639177 -0.89388353 -1.03139416 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.28736767 -0.63153633 -1.10570813 ...  0.         -0.21330916\n",
      "  -0.19036084]\n",
      " [-0.31871478 -0.70161538 -0.59789595 ...  0.         -0.20850931\n",
      "  -0.18526754]\n",
      " ...\n",
      " [-0.38969913 -0.84716417 -1.08093681 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.39051951 -0.75552234 -1.04377982 ...  0.         -0.24210825\n",
      "  -0.22092067]\n",
      " [-0.3338702  -0.37457982  0.87599793 ...  0.         -0.24210825\n",
      "  -0.22092067]]\n",
      "\n",
      "Нормализованные числовые признаки тестовой выборки:\n",
      "[[0.00503169 0.0100848  0.0186428  ... 0.         0.         0.        ]\n",
      " [0.0102984  0.04354802 0.01416853 ... 0.         0.00149254 0.0015    ]\n",
      " [0.0075013  0.03460921 0.04474273 ... 0.         0.00174129 0.00175   ]\n",
      " ...\n",
      " [0.00116738 0.01604401 0.01565996 ... 0.         0.         0.        ]\n",
      " [0.00109418 0.02773321 0.01789709 ... 0.         0.         0.        ]\n",
      " [0.00614899 0.07632363 0.13348248 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных из CSV файлов\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "val_data = pd.read_csv('val_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Разделение числовых признаков и целевой переменной\n",
    "numerical_features = ['genergy', 'gpuls', 'gdenergy', 'gdpuls', 'nbumps', 'nbumps2', 'nbumps3', \n",
    "                      'nbumps4', 'nbumps5', 'nbumps6', 'nbumps7', 'nbumps89', 'energy', 'maxenergy']\n",
    "\n",
    "X_train = train_data[numerical_features]\n",
    "y_train = train_data['class']\n",
    "\n",
    "X_val = val_data[numerical_features]\n",
    "y_val = val_data['class']\n",
    "\n",
    "X_test = test_data[numerical_features]\n",
    "y_test = test_data['class']\n",
    "\n",
    "# Инициализация и обучение scaler'ов\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Проверка наличия данных перед масштабированием\n",
    "if not X_train.empty:\n",
    "    # Стандартизация признаков\n",
    "    X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "    # Нормализация признаков\n",
    "    X_train_normalized = minmax_scaler.fit_transform(X_train)\n",
    "    print(\"Масштабирование числовых признаков обучающей выборки выполнено.\")\n",
    "    print(\"Масштабированные числовые признаки обучающей выборки (стандартизация):\")\n",
    "    print(X_train_scaled)\n",
    "    print(\"\\nНормализованные числовые признаки обучающей выборки:\")\n",
    "    print(X_train_normalized)\n",
    "else:\n",
    "    print(\"Ошибка: Не удалось найти данные для масштабирования числовых признаков обучающей выборки.\")\n",
    "\n",
    "if not X_val.empty:\n",
    "    # Стандартизация признаков\n",
    "    X_val_scaled = standard_scaler.transform(X_val)\n",
    "    # Нормализация признаков\n",
    "    X_val_normalized = minmax_scaler.transform(X_val)\n",
    "    print(\"Масштабирование числовых признаков валидационной выборки выполнено.\")\n",
    "    print(\"\\nМасштабированные числовые признаки валидационной выборки (стандартизация):\")\n",
    "    print(X_val_scaled)\n",
    "    print(\"\\nНормализованные числовые признаки валидационной выборки:\")\n",
    "    print(X_val_normalized)\n",
    "else:\n",
    "    print(\"Ошибка: Не удалось найти данные для масштабирования числовых признаков валидационной выборки.\")\n",
    "\n",
    "if not X_test.empty:\n",
    "    # Стандартизация признаков\n",
    "    X_test_scaled = standard_scaler.transform(X_test)\n",
    "    # Нормализация признаков\n",
    "    X_test_normalized = minmax_scaler.transform(X_test)\n",
    "    print(\"Масштабирование числовых признаков тестовой выборки выполнено.\")\n",
    "    print(\"\\nМасштабированные числовые признаки тестовой выборки (стандартизация):\")\n",
    "    print(X_test_scaled)\n",
    "    print(\"\\nНормализованные числовые признаки тестовой выборки:\")\n",
    "    print(X_test_normalized)\n",
    "else:\n",
    "    print(\"Ошибка: Не удалось найти данные для масштабирования числовых признаков тестовой выборки.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:37:51.780750Z",
     "start_time": "2024-04-29T16:37:51.602635Z"
    }
   },
   "id": "710d2dfc3fe9ad6",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. С использованием библиотеки scikit-learn обучить 2 модели нейронной сети (Perceptron и MLPClassifier) по обучающей выборке. Перед обучением необходимо осуществить масштабирование признаков. Пример MLPClassifier Пример и описание Perceptron"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "687efa872a5b9b2f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели нейронной сети обучены успешно.\n"
     ]
    }
   ],
   "source": [
    "# Инициализация моделей с увеличенным количеством итераций\n",
    "perceptron_model = Perceptron(random_state=42)\n",
    "mlp_model = MLPClassifier(random_state=42, max_iter=1000, tol=1e-4)  # Установка max_iter на 500\n",
    "\n",
    "# Обучение моделей\n",
    "perceptron_model.fit(X_train_scaled, y_train)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Модели нейронной сети обучены успешно.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:39:01.929433Z",
     "start_time": "2024-04-29T16:38:58.874376Z"
    }
   },
   "id": "1b8e9ed5d6dd29fb",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Проверить точность модели по тестовой выборке."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3efea1eb7979fe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность Perceptron на тестовой выборке: 0.9226804123711341\n",
      "Точность MLPClassifier на тестовой выборке: 0.9278350515463918\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества моделей на тестовой выборке\n",
    "perceptron_test_accuracy = perceptron_model.score(X_test_scaled, y_test)\n",
    "mlp_test_accuracy = mlp_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Точность Perceptron на тестовой выборке:\", perceptron_test_accuracy)\n",
    "print(\"Точность MLPClassifier на тестовой выборке:\", mlp_test_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:39:04.604568Z",
     "start_time": "2024-04-29T16:39:04.569791Z"
    }
   },
   "id": "67136041ceb7fc80",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Провести эксперименты и определить наилучшие параметры коэффициента обучения, параметра регуляризации, функции оптимизации. Данные экспериментов необходимо представить в отчете (графики, ход проведения эксперимента, выводы)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79c31250257242e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'alpha': 0.0001, 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "Точность наилучшей модели на валидационной выборке: 0.9341822133117033\n",
      "Точность модели на тестовой выборке: 0.9304123711340206\n"
     ]
    }
   ],
   "source": [
    "# Задаем диапазоны значений параметров для перебора\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "# Создаем экземпляр модели MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42, max_iter=2000)\n",
    "\n",
    "# Инициализируем GridSearchCV для перебора параметров\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Обучаем GridSearchCV на обучающей выборке\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Получаем наилучшие параметры и точность на валидационной выборке\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Наилучшие параметры:\", best_params)\n",
    "print(\"Точность наилучшей модели на валидационной выборке:\", best_accuracy)\n",
    "\n",
    "# Используем наилучшие параметры для обучения модели на всей обучающей выборке\n",
    "best_mlp = MLPClassifier(random_state=42, max_iter=2000, **best_params)\n",
    "best_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Оцениваем качество модели на тестовой выборке\n",
    "test_accuracy = best_mlp.score(X_test_scaled, y_test)\n",
    "print(\"Точность модели на тестовой выборке:\", test_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:35:41.335594Z",
     "start_time": "2024-04-29T16:32:31.177946Z"
    }
   },
   "id": "9359a664840912d8",
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
